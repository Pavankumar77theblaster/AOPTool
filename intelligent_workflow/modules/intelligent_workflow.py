#!/usr/bin/env python3
"""
ReconBuster v3.0 - Intelligent Workflow Orchestrator
Automatically chains tools based on findings for continuous vulnerability discovery

Features:
- Automatic tool chaining based on discoveries
- Service-specific vulnerability testing
- Smart decision making (if port open → test service vulnerabilities)
- Real-time progress tracking
- Exploitation after detection
"""

import asyncio
import aiohttp
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field
from datetime import datetime
import json

# Import all scanners
from .port_scanner import PortScanner, PortResult
from .bypass403_v3 import Bypass403Engine
from .kali_tools_integration import KaliToolsIntegrator
from .owasp_advanced_scanner import OWASPAdvancedScanner
from .subdomain import SubdomainEnumerator
from .waf_detector import WAFDetector
from .ssl_analyzer import SSLAnalyzer
from .cms_detector import CMSDetector


@dataclass
class WorkflowStep:
    """A step in the workflow"""
    step_id: str
    tool_name: str
    description: str
    status: str  # pending, running, completed, failed
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    findings: List[Dict] = field(default_factory=list)
    triggered_by: Optional[str] = None  # What finding triggered this step
    next_steps: List[str] = field(default_factory=list)  # Steps to run next


@dataclass
class Finding:
    """A vulnerability/discovery finding"""
    finding_id: str
    source_tool: str
    severity: str  # critical, high, medium, low, info
    title: str
    description: str
    evidence: Dict
    timestamp: datetime = field(default_factory=datetime.now)
    triggers: List[str] = field(default_factory=list)  # Tools to trigger next


class IntelligentWorkflow:
    """
    Intelligent Workflow Orchestrator
    Automatically chains tools based on what is discovered
    """

    def __init__(self, target: str, config: Dict = None):
        self.target = target
        self.config = config or {}
        self.workflow_steps: List[WorkflowStep] = []
        self.findings: List[Finding] = []
        self.completed_steps: set = set()
        self.running_steps: set = set()

        # Progress callback
        self.progress_callback: Optional[Callable] = None

        # Session
        self.session: Optional[aiohttp.ClientSession] = None

    async def run(self, progress_callback: Optional[Callable] = None):
        """
        Execute intelligent workflow
        """
        self.progress_callback = progress_callback

        async with aiohttp.ClientSession() as self.session:

            # Phase 1: Initial Reconnaissance
            await self._emit_progress("Starting Intelligent Workflow", "info")

            # Step 1: Port Scanning (Foundation)
            port_findings = await self._run_port_scan()

            # Step 2: Based on open ports, run service-specific tests
            if port_findings:
                await self._run_service_specific_tests(port_findings)

            # Step 3: Web Discovery (if web ports found)
            web_ports = self._extract_web_ports(port_findings)
            if web_ports:
                await self._run_web_discovery(web_ports)

            # Step 4: Database Testing (if DB ports found)
            db_ports = self._extract_database_ports(port_findings)
            if db_ports:
                await self._run_database_tests(db_ports)

            # Step 5: Subdomain Enumeration
            subdomains = await self._run_subdomain_enum()

            # Step 6: Test each subdomain for vulnerabilities
            if subdomains:
                await self._test_subdomains(subdomains)

            # Step 7: Advanced OWASP Testing on discovered endpoints
            await self._run_advanced_owasp_tests()

            # Phase 2: Vulnerability Exploitation
            await self._run_exploitation_phase()

            # Generate workflow report
            return self._generate_workflow_report()

    async def _run_port_scan(self) -> List[PortResult]:
        """
        Step 1: Port Scanning
        Returns: List of open ports with service info
        """
        step = WorkflowStep(
            step_id="port_scan",
            tool_name="Port Scanner",
            description="Scanning ports to discover running services",
            status="running"
        )
        step.started_at = datetime.now()
        self.workflow_steps.append(step)
        self.running_steps.add("port_scan")

        await self._emit_progress(f"[Port Scanner] Scanning {self.target}...", "info")

        try:
            scanner = PortScanner(
                target=self.target,
                timeout=3,
                threads=100
            )

            # Scan top 100 ports
            open_ports = await scanner.scan_top_ports()

            step.status = "completed"
            step.completed_at = datetime.now()
            step.findings = [
                {
                    "port": p.port,
                    "service": p.service,
                    "version": p.version,
                    "banner": p.banner,
                    "state": p.state
                }
                for p in open_ports
            ]

            # Add findings
            for port in open_ports:
                finding = Finding(
                    finding_id=f"port_{port.port}",
                    source_tool="port_scanner",
                    severity="info",
                    title=f"Open Port: {port.port}/{port.service}",
                    description=f"Port {port.port} is open running {port.service}",
                    evidence={
                        "port": port.port,
                        "service": port.service,
                        "version": port.version,
                        "banner": port.banner
                    },
                    triggers=self._get_triggers_for_port(port)
                )
                self.findings.append(finding)

            self.completed_steps.add("port_scan")
            self.running_steps.remove("port_scan")

            await self._emit_progress(
                f"[Port Scanner] Found {len(open_ports)} open ports",
                "success"
            )

            return open_ports

        except Exception as e:
            step.status = "failed"
            step.completed_at = datetime.now()
            await self._emit_progress(f"[Port Scanner] Error: {e}", "error")
            return []

    def _get_triggers_for_port(self, port: PortResult) -> List[str]:
        """
        Determine which tools to trigger based on discovered port/service
        """
        triggers = []

        # Web services → Web vulnerability testing
        if port.port in [80, 443, 8080, 8443, 8000, 8888, 3000, 4443]:
            triggers.extend([
                "nuclei_web",
                "ffuf_directory",
                "bypass_403",
                "owasp_advanced",
                "waf_detection",
                "ssl_analysis" if port.port in [443, 8443, 4443] else None
            ])

        # SSH → Brute force, weak config
        if port.service == "ssh" or port.port == 22:
            triggers.extend(["ssh_audit", "hydra_ssh"])

        # FTP → Anonymous login, brute force
        if port.service == "ftp" or port.port == 21:
            triggers.extend(["ftp_anon_check", "hydra_ftp"])

        # Databases → SQLMap, default creds
        if port.service in ["mysql", "postgresql", "mssql", "oracle", "mongodb", "redis"]:
            triggers.extend(["database_test", "sqlmap", "default_creds"])

        # SMB/RDP → Eternal Blue, weak passwords
        if port.port in [445, 139, 3389]:
            triggers.extend(["smb_vulnerabilities", "hydra_rdp"])

        # DNS → Zone transfer, subdomain brute force
        if port.service == "dns" or port.port == 53:
            triggers.extend(["dns_enum", "zone_transfer"])

        return [t for t in triggers if t]

    async def _run_service_specific_tests(self, port_findings: List[PortResult]):
        """
        Step 2: Run service-specific vulnerability tests based on discovered ports
        """
        await self._emit_progress(
            f"[Service Testing] Running service-specific tests on {len(port_findings)} ports",
            "info"
        )

        tasks = []

        for port in port_findings:
            # Web services
            if port.port in [80, 443, 8080, 8443, 8000, 8888]:
                tasks.append(self._test_web_service(port))

            # SSH
            if port.service == "ssh" or port.port == 22:
                tasks.append(self._test_ssh_service(port))

            # FTP
            if port.service == "ftp" or port.port == 21:
                tasks.append(self._test_ftp_service(port))

            # MySQL
            if port.service == "mysql" or port.port == 3306:
                tasks.append(self._test_mysql_service(port))

            # PostgreSQL
            if port.service == "postgresql" or port.port == 5432:
                tasks.append(self._test_postgresql_service(port))

            # MongoDB
            if port.service == "mongodb" or port.port == 27017:
                tasks.append(self._test_mongodb_service(port))

            # Redis
            if port.service == "redis" or port.port == 6379:
                tasks.append(self._test_redis_service(port))

            # SMB
            if port.port in [445, 139]:
                tasks.append(self._test_smb_service(port))

        # Run all service tests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)

        await self._emit_progress(
            f"[Service Testing] Completed testing {len(tasks)} services",
            "success"
        )

    async def _test_web_service(self, port: PortResult):
        """Test web service vulnerabilities"""
        url = f"http{'s' if port.port in [443, 8443, 4443] else ''}://{self.target}:{port.port}"

        await self._emit_progress(f"[Web Test] Testing {url}", "info")

        step = WorkflowStep(
            step_id=f"web_test_{port.port}",
            tool_name=f"Web Vulnerability Test (Port {port.port})",
            description=f"Testing web vulnerabilities on {url}",
            status="running",
            triggered_by=f"port_{port.port}"
        )
        step.started_at = datetime.now()
        self.workflow_steps.append(step)

        findings_count = 0

        try:
            # 1. WAF Detection
            waf_detector = WAFDetector(url, self.session)
            waf_result = await waf_detector.detect()
            if waf_result:
                step.findings.append({"type": "waf", "detected": waf_result})
                findings_count += 1

            # 2. Nuclei Scan
            integrator = KaliToolsIntegrator(url)
            nuclei_result = await integrator.run_nuclei(severity=["critical", "high"])
            if nuclei_result.success and nuclei_result.findings:
                step.findings.extend(nuclei_result.findings)
                findings_count += len(nuclei_result.findings)

                # Add high/critical findings
                for finding in nuclei_result.findings:
                    self.findings.append(Finding(
                        finding_id=f"nuclei_{port.port}_{len(self.findings)}",
                        source_tool="nuclei",
                        severity=finding.get("severity", "medium"),
                        title=finding.get("name", "Nuclei Finding"),
                        description=finding.get("description", ""),
                        evidence=finding
                    ))

            # 3. Directory Fuzzing
            ffuf_result = await integrator.run_ffuf(rate=50)
            if ffuf_result.success and ffuf_result.findings:
                step.findings.extend(ffuf_result.findings)
                findings_count += len(ffuf_result.findings)

                # Test 403 bypasses on forbidden directories
                for dir_finding in ffuf_result.findings:
                    if dir_finding.get("status") == 403:
                        forbidden_url = dir_finding.get("url")
                        await self._test_403_bypass(forbidden_url, port.port)

            # 4. CMS Detection
            cms_detector = CMSDetector(url, self.session)
            cms_result = await cms_detector.detect()
            if cms_result:
                step.findings.append({"type": "cms", "detected": cms_result})
                findings_count += 1

                # If WordPress → Run WPScan
                if "wordpress" in cms_result.lower():
                    await self._run_wpscan(url, port.port)

            # 5. OWASP Advanced Tests
            owasp_scanner = OWASPAdvancedScanner(url, self.session)

            # CSRF
            csrf_findings = await owasp_scanner.test_csrf(url)
            if csrf_findings:
                step.findings.extend([f.__dict__ for f in csrf_findings])
                self.findings.extend(csrf_findings)
                findings_count += len(csrf_findings)

            # Mass Assignment
            mass_findings = await owasp_scanner.test_mass_assignment(url)
            if mass_findings:
                step.findings.extend([f.__dict__ for f in mass_findings])
                self.findings.extend(mass_findings)
                findings_count += len(mass_findings)

            step.status = "completed"
            step.completed_at = datetime.now()

            await self._emit_progress(
                f"[Web Test] Found {findings_count} issues on port {port.port}",
                "success" if findings_count > 0 else "info"
            )

        except Exception as e:
            step.status = "failed"
            step.completed_at = datetime.now()
            await self._emit_progress(f"[Web Test] Error on port {port.port}: {e}", "error")

    async def _test_403_bypass(self, url: str, port: int):
        """Test 403 bypass on forbidden URL"""
        await self._emit_progress(f"[403 Bypass] Testing {url}", "info")

        try:
            bypass_engine = Bypass403Engine(url, threads=10)
            bypasses = await bypass_engine.run()

            if bypasses:
                for bypass in bypasses:
                    self.findings.append(Finding(
                        finding_id=f"bypass_403_{port}_{len(self.findings)}",
                        source_tool="bypass403_v3",
                        severity="high" if bypass.confidence == "high" else "medium",
                        title=f"403 Bypass Found: {bypass.technique}",
                        description=bypass.evidence,
                        evidence={
                            "url": bypass.bypass_url,
                            "technique": bypass.technique,
                            "confidence": bypass.confidence,
                            "status_change": f"{bypass.baseline.status_code} → {bypass.response_status}"
                        }
                    ))

                await self._emit_progress(
                    f"[403 Bypass] Found {len(bypasses)} valid bypasses",
                    "warning"
                )
        except Exception as e:
            await self._emit_progress(f"[403 Bypass] Error: {e}", "error")

    async def _run_wpscan(self, url: str, port: int):
        """Run WPScan on WordPress site"""
        await self._emit_progress(f"[WPScan] Scanning WordPress at {url}", "info")

        integrator = KaliToolsIntegrator(url)
        # Note: WPScan would need to be added to kali_tools_integration.py
        # For now, log the intent
        await self._emit_progress(f"[WPScan] WordPress detected, manual WPScan recommended", "info")

    async def _test_ssh_service(self, port: PortResult):
        """Test SSH service"""
        await self._emit_progress(f"[SSH Test] Testing SSH on port {port.port}", "info")

        # Check for SSH vulnerabilities
        # - Weak algorithms
        # - Banner grab for version
        # - Check if password auth enabled

        finding = Finding(
            finding_id=f"ssh_{port.port}",
            source_tool="ssh_audit",
            severity="info",
            title=f"SSH Service Detected",
            description=f"SSH running on port {port.port}: {port.version}",
            evidence={"banner": port.banner, "version": port.version},
            triggers=["hydra_ssh"]  # Can trigger brute force
        )
        self.findings.append(finding)

    async def _test_ftp_service(self, port: PortResult):
        """Test FTP service"""
        await self._emit_progress(f"[FTP Test] Testing FTP on port {port.port}", "info")

        # Check for anonymous login
        finding = Finding(
            finding_id=f"ftp_{port.port}",
            source_tool="ftp_audit",
            severity="info",
            title=f"FTP Service Detected",
            description=f"FTP running on port {port.port}",
            evidence={"banner": port.banner},
            triggers=["ftp_anon_check", "hydra_ftp"]
        )
        self.findings.append(finding)

    async def _test_mysql_service(self, port: PortResult):
        """Test MySQL database"""
        await self._emit_progress(f"[MySQL Test] Testing MySQL on port {port.port}", "info")

        # SQLMap integration
        url = f"http://{self.target}:{port.port}"
        integrator = KaliToolsIntegrator(url)

        # Note: This would need actual SQL injection points
        # For now, just document the finding
        finding = Finding(
            finding_id=f"mysql_{port.port}",
            source_tool="mysql_audit",
            severity="medium",
            title=f"MySQL Database Exposed",
            description=f"MySQL running on port {port.port}",
            evidence={"version": port.version, "banner": port.banner},
            triggers=["sqlmap", "default_creds"]
        )
        self.findings.append(finding)

    async def _test_postgresql_service(self, port: PortResult):
        """Test PostgreSQL database"""
        await self._emit_progress(f"[PostgreSQL Test] Testing on port {port.port}", "info")

        finding = Finding(
            finding_id=f"postgresql_{port.port}",
            source_tool="postgresql_audit",
            severity="medium",
            title=f"PostgreSQL Database Exposed",
            description=f"PostgreSQL running on port {port.port}",
            evidence={"version": port.version},
            triggers=["default_creds"]
        )
        self.findings.append(finding)

    async def _test_mongodb_service(self, port: PortResult):
        """Test MongoDB database"""
        await self._emit_progress(f"[MongoDB Test] Testing on port {port.port}", "info")

        finding = Finding(
            finding_id=f"mongodb_{port.port}",
            source_tool="mongodb_audit",
            severity="high",
            title=f"MongoDB Database Exposed",
            description=f"MongoDB running on port {port.port} - Check for no-auth access",
            evidence={"port": port.port},
            triggers=["mongodb_noauth_check"]
        )
        self.findings.append(finding)

    async def _test_redis_service(self, port: PortResult):
        """Test Redis service"""
        await self._emit_progress(f"[Redis Test] Testing on port {port.port}", "info")

        finding = Finding(
            finding_id=f"redis_{port.port}",
            source_tool="redis_audit",
            severity="critical",
            title=f"Redis Database Exposed",
            description=f"Redis running on port {port.port} - High risk of RCE if unprotected",
            evidence={"port": port.port, "banner": port.banner},
            triggers=["redis_rce_check"]
        )
        self.findings.append(finding)

    async def _test_smb_service(self, port: PortResult):
        """Test SMB service"""
        await self._emit_progress(f"[SMB Test] Testing on port {port.port}", "info")

        finding = Finding(
            finding_id=f"smb_{port.port}",
            source_tool="smb_audit",
            severity="high",
            title=f"SMB Service Detected",
            description=f"SMB on port {port.port} - Check for EternalBlue, null sessions",
            evidence={"port": port.port},
            triggers=["eternal_blue_check", "smb_enum"]
        )
        self.findings.append(finding)

    def _extract_web_ports(self, port_findings: List[PortResult]) -> List[int]:
        """Extract web ports from findings"""
        return [p.port for p in port_findings if p.port in [80, 443, 8080, 8443, 8000, 8888, 3000, 4443]]

    def _extract_database_ports(self, port_findings: List[PortResult]) -> List[int]:
        """Extract database ports"""
        db_ports = [3306, 5432, 1433, 1521, 27017, 6379]
        return [p.port for p in port_findings if p.port in db_ports]

    async def _run_web_discovery(self, web_ports: List[int]):
        """Web-specific discovery on web ports"""
        await self._emit_progress(f"[Web Discovery] Testing {len(web_ports)} web ports", "info")
        # Already handled in _test_web_service

    async def _run_database_tests(self, db_ports: List[int]):
        """Database-specific tests"""
        await self._emit_progress(f"[Database Tests] Testing {len(db_ports)} database ports", "info")
        # Already handled in service-specific tests

    async def _run_subdomain_enum(self) -> List[str]:
        """Subdomain enumeration"""
        await self._emit_progress(f"[Subdomain Enum] Discovering subdomains", "info")

        try:
            enumerator = SubdomainEnumerator(self.target)
            subdomains = await enumerator.enumerate(verify=True)

            await self._emit_progress(
                f"[Subdomain Enum] Found {len(subdomains)} subdomains",
                "success"
            )

            return [s['subdomain'] for s in subdomains if 'subdomain' in s]
        except Exception as e:
            await self._emit_progress(f"[Subdomain Enum] Error: {e}", "error")
            return []

    async def _test_subdomains(self, subdomains: List[str]):
        """Test each discovered subdomain"""
        await self._emit_progress(
            f"[Subdomain Testing] Testing {len(subdomains[:10])} subdomains (limited to 10)",
            "info"
        )

        # Test first 10 subdomains to avoid overload
        for subdomain in subdomains[:10]:
            # Run port scan on subdomain
            # Run web tests if web ports found
            pass  # Implement as needed

    async def _run_advanced_owasp_tests(self):
        """Run advanced OWASP tests"""
        await self._emit_progress(f"[OWASP Tests] Running advanced vulnerability tests", "info")
        # Already handled in web service testing

    async def _run_exploitation_phase(self):
        """Exploitation phase - exploit discovered vulnerabilities"""
        await self._emit_progress(f"[Exploitation] Analyzing findings for exploitation", "info")

        critical_findings = [f for f in self.findings if f.severity == "critical"]
        high_findings = [f for f in self.findings if f.severity == "high"]

        await self._emit_progress(
            f"[Exploitation] Found {len(critical_findings)} critical and {len(high_findings)} high severity issues",
            "warning" if (critical_findings or high_findings) else "info"
        )

    def _generate_workflow_report(self) -> Dict:
        """Generate comprehensive workflow report"""
        return {
            "target": self.target,
            "total_steps": len(self.workflow_steps),
            "completed_steps": len(self.completed_steps),
            "total_findings": len(self.findings),
            "findings_by_severity": {
                "critical": len([f for f in self.findings if f.severity == "critical"]),
                "high": len([f for f in self.findings if f.severity == "high"]),
                "medium": len([f for f in self.findings if f.severity == "medium"]),
                "low": len([f for f in self.findings if f.severity == "low"]),
                "info": len([f for f in self.findings if f.severity == "info"]),
            },
            "workflow_steps": [
                {
                    "step_id": s.step_id,
                    "tool_name": s.tool_name,
                    "status": s.status,
                    "findings_count": len(s.findings),
                    "duration": (s.completed_at - s.started_at).total_seconds() if s.completed_at and s.started_at else 0
                }
                for s in self.workflow_steps
            ],
            "findings": [
                {
                    "id": f.finding_id,
                    "tool": f.source_tool,
                    "severity": f.severity,
                    "title": f.title,
                    "description": f.description,
                    "evidence": f.evidence,
                    "triggers": f.triggers
                }
                for f in self.findings
            ]
        }

    async def _emit_progress(self, message: str, level: str = "info"):
        """Emit progress update"""
        if self.progress_callback:
            await self.progress_callback({
                "timestamp": datetime.now().isoformat(),
                "level": level,
                "message": message
            })
        else:
            # Print to console
            colors = {
                "info": "\033[96m",
                "success": "\033[92m",
                "warning": "\033[93m",
                "error": "\033[91m",
                "reset": "\033[0m"
            }
            print(f"{colors.get(level, colors['info'])}{message}{colors['reset']}")


# Test function
async def main():
    import sys

    if len(sys.argv) < 2:
        print("Usage: python intelligent_workflow.py <target>")
        sys.exit(1)

    target = sys.argv[1]

    workflow = IntelligentWorkflow(target)
    report = await workflow.run()

    print("\n" + "="*80)
    print("WORKFLOW REPORT")
    print("="*80)
    print(json.dumps(report, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
